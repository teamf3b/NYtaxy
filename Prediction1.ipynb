{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'lubridate'\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    date\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(ggplot2)  # Plotting\n",
    "library(gridExtra)  # Grid plotting\n",
    "library(geosphere) # Spatial coordinates\n",
    "library(caret) # Prediction\n",
    "library(Metrics)  # Error measurement\n",
    "library(lubridate) #Date et Heure\n",
    "\n",
    "#library(\"GGally\", lib.loc=\"/Library/Frameworks/R.framework/Versions/3.5/Resources/library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_raw = read.csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reduce the dataframe size to be more workable\n",
    "\n",
    "N = 1000\n",
    "train_dataset = train_dataset_raw[sample(nrow(train_dataset_raw), N), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter some absurd values:\n",
    "\n",
    "# Trips too long\n",
    "MAX_TRIP_DURATION = 2 * 3600\n",
    "MIN_TRIP_DURATION = 30\n",
    "train_dataset = train_dataset[\n",
    "    train_dataset$trip_duration < MAX_TRIP_DURATION &\n",
    "    train_dataset$trip_duration > MIN_TRIP_DURATION,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distHaversine\n",
    "\n",
    "train_dataset$distHaversine = numeric(length(train_dataset$dropoff_latitude))\n",
    "for (i in 1:length(train_dataset$dropoff_latitude)) {\n",
    "    train_dataset$distHaversine[i] = distm(\n",
    "        c(train_dataset$pickup_longitude[i], train_dataset$pickup_latitude[i]),\n",
    "        c(train_dataset$dropoff_longitude[i], train_dataset$dropoff_latitude[i]),\n",
    "        fun = distHaversine\n",
    "    )\n",
    "}\n",
    "\n",
    "# log_trip duration\n",
    "\n",
    "train_dataset$log_trip_duration = log(train_dataset$trip_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ERROR",
     "evalue": "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): impossible de démarrer le périphérique png()\n",
     "output_type": "error",
     "traceback": [
      "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): impossible de démarrer le périphérique png()\nTraceback:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot() + \n",
    "  geom_point(data = train_dataset, \n",
    "             aes(x = distHaversine, y = trip_duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date et Heure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset$pickup_month <- month(train_dataset$pickup_datetime)\n",
    "train_dataset$pickup_hour <- hour(train_dataset$pickup_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ajout de l'heure de départ en secondes\n",
    "x=as.character(train_dataset$pickup_datetime);\n",
    "dtparts = t(as.data.frame(strsplit(x,' ')));\n",
    "train_dataset$pickup_hour_in_seconds=as.numeric(as.duration(hms(dtparts[,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création d'une colonne pour les jours de la semaine en character et en numeric\n",
    "y=as.Date(train_dataset$pickup_datetime);\n",
    "train_dataset$pickup_day=format(y, \"%A\")\n",
    "\n",
    "#Transformation en numeric pour les besoins éventuels de l'algorithme de prediction\n",
    "jour=c(\"dimanche\",\"lundi\",\"mardi\",\"mercredi\",\"jeudi\",\"vendredi\",\"samedi\")\n",
    "train_dataset$pickup_day_numeric <- train_dataset$pickup_day\n",
    "for (i in 1:10){\n",
    "    train_dataset$pickup_day_numeric[train_dataset$pickup_day_numeric==jour[i]] <- i\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vitesse moyenne pour une course\n",
    "train_dataset$speed <- (train_dataset$distHaversine/train_dataset$trip_duration)\n",
    "\n",
    "#vitesse moyenne par tranche horaire (1h)\n",
    "train_dataset$meanspeedhour <- train_dataset$speed\n",
    "for (i in 0:23){\n",
    "    train_dataset$meanspeedhour[train_dataset$pickup_hour==i] <- mean(train_dataset$meanspeedhour[train_dataset$pickup_hour==i])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): impossible de démarrer le périphérique png()\n",
     "output_type": "error",
     "traceback": [
      "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): impossible de démarrer le périphérique png()\nTraceback:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(train_dataset$meanspeedhour~train_dataset$pickup_hour, train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(998)\n",
    "inTraining <- createDataPartition(train_dataset$trip_duration, p = .75, list = FALSE)\n",
    "training <- train_dataset[ inTraining,]\n",
    "testing  <- train_dataset[-inTraining,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitControl <- trainControl(## 10-fold CV\n",
    "                           method = \"repeatedcv\",\n",
    "                           number = 2,\n",
    "                           ## repeated ten times\n",
    "                           repeats = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "earth_predictor <- train(trip_duration ~ distHaversine, data = training, \n",
    "                 method = \"earth\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Multivariate Adaptive Regression Spline \n",
       "\n",
       "76 samples\n",
       " 1 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Bootstrapped (25 reps) \n",
       "Summary of sample sizes: 76, 76, 76, 76, 76, 76, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  nprune  RMSE      Rsquared   MAE     \n",
       "  2       778.7368  0.4636976  410.1444\n",
       "  3       650.9047  0.6720712  319.1000\n",
       "  5       653.3585  0.6717722  320.7685\n",
       "\n",
       "Tuning parameter 'degree' was held constant at a value of 1\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final values used for the model were nprune = 3 and degree = 1."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing$prediction = predict(earth_predictor, testing)\n",
    "testing$error = abs(testing$trip_duration - testing$prediction)\n",
    "\n",
    "gbmFit1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.93984230410556"
      ],
      "text/latex": [
       "1.93984230410556"
      ],
      "text/markdown": [
       "1.93984230410556"
      ],
      "text/plain": [
       "[1] 1.939842"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmsle(testing$trip_duration, testing$error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitControl <- trainControl(## 10-fold CV\n",
    "                           method = \"repeatedcv\",\n",
    "                           number = 2,\n",
    "                           ## repeated ten times\n",
    "                           repeats = 2,\n",
    ")\n",
    "xgbLinear_predictor <- train(trip_duration ~ distHaversine + pickup_longitude + pickup_latitude + dropoff_longitude + dropoff_latitude , data = training, \n",
    "                 method = \"xgbLinear\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eXtreme Gradient Boosting \n",
       "\n",
       "747 samples\n",
       "  5 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Bootstrapped (25 reps) \n",
       "Summary of sample sizes: 747, 747, 747, 747, 747, 747, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  lambda  alpha  nrounds  RMSE      Rsquared   MAE     \n",
       "  0e+00   0e+00   50      451.2267  0.5320722  296.8659\n",
       "  0e+00   0e+00  100      452.2365  0.5307044  298.0345\n",
       "  0e+00   0e+00  150      452.3765  0.5305273  298.1847\n",
       "  0e+00   1e-04   50      451.2266  0.5320722  296.8659\n",
       "  0e+00   1e-04  100      452.2032  0.5307338  298.0327\n",
       "  0e+00   1e-04  150      452.3312  0.5305634  298.1683\n",
       "  0e+00   1e-01   50      451.3459  0.5316088  297.2384\n",
       "  0e+00   1e-01  100      452.5354  0.5300642  298.5491\n",
       "  0e+00   1e-01  150      452.6653  0.5299060  298.6691\n",
       "  1e-04   0e+00   50      451.4913  0.5315324  296.8014\n",
       "  1e-04   0e+00  100      452.3815  0.5304278  298.0265\n",
       "  1e-04   0e+00  150      452.4665  0.5303036  298.1339\n",
       "  1e-04   1e-04   50      451.4913  0.5315324  296.8014\n",
       "  1e-04   1e-04  100      452.3692  0.5304460  298.0207\n",
       "  1e-04   1e-04  150      452.4505  0.5303266  298.1281\n",
       "  1e-04   1e-01   50      451.2946  0.5313901  297.0298\n",
       "  1e-04   1e-01  100      452.2433  0.5302292  298.0923\n",
       "  1e-04   1e-01  150      452.3253  0.5301582  298.2091\n",
       "  1e-01   0e+00   50      446.5523  0.5370134  293.8532\n",
       "  1e-01   0e+00  100      447.8617  0.5351017  295.3057\n",
       "  1e-01   0e+00  150      447.9708  0.5349577  295.4606\n",
       "  1e-01   1e-04   50      446.5522  0.5370134  293.8532\n",
       "  1e-01   1e-04  100      447.8710  0.5350793  295.3203\n",
       "  1e-01   1e-04  150      447.9888  0.5349179  295.4874\n",
       "  1e-01   1e-01   50      445.9486  0.5374040  293.5222\n",
       "  1e-01   1e-01  100      447.1120  0.5357369  294.6768\n",
       "  1e-01   1e-01  150      447.2359  0.5355478  294.8080\n",
       "\n",
       "Tuning parameter 'eta' was held constant at a value of 0.3\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final values used for the model were nrounds = 50, lambda = 0.1, alpha\n",
       " = 0.1 and eta = 0.3."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1.83683115730834"
      ],
      "text/latex": [
       "1.83683115730834"
      ],
      "text/markdown": [
       "1.83683115730834"
      ],
      "text/plain": [
       "[1] 1.836831"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing$prediction = predict(xgbLinear_predictor, testing)\n",
    "testing$error = abs(testing$trip_duration - testing$prediction)\n",
    "\n",
    "xgbLinear_predictor\n",
    "\n",
    "rmsle(testing$trip_duration, testing$error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we try with the log of the trip_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eXtreme Gradient Boosting \n",
       "\n",
       "747 samples\n",
       "  5 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Bootstrapped (25 reps) \n",
       "Summary of sample sizes: 747, 747, 747, 747, 747, 747, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  lambda  alpha  nrounds  RMSE       Rsquared   MAE      \n",
       "  0e+00   0e+00   50      0.5066993  0.5429062  0.3865567\n",
       "  0e+00   0e+00  100      0.5084566  0.5406506  0.3880234\n",
       "  0e+00   0e+00  150      0.5086983  0.5403393  0.3882290\n",
       "  0e+00   1e-04   50      0.5071212  0.5421257  0.3865666\n",
       "  0e+00   1e-04  100      0.5091420  0.5394565  0.3884212\n",
       "  0e+00   1e-04  150      0.5093684  0.5391555  0.3886401\n",
       "  0e+00   1e-01   50      0.5021277  0.5505189  0.3810175\n",
       "  0e+00   1e-01  100      0.5041168  0.5480770  0.3825638\n",
       "  0e+00   1e-01  150      0.5041412  0.5480536  0.3825817\n",
       "  1e-04   0e+00   50      0.5054963  0.5443707  0.3855320\n",
       "  1e-04   0e+00  100      0.5074458  0.5417921  0.3871490\n",
       "  1e-04   0e+00  150      0.5076769  0.5414960  0.3873818\n",
       "  1e-04   1e-04   50      0.5050919  0.5452419  0.3849003\n",
       "  1e-04   1e-04  100      0.5070041  0.5427278  0.3864428\n",
       "  1e-04   1e-04  150      0.5071525  0.5425500  0.3865712\n",
       "  1e-04   1e-01   50      0.5017825  0.5508997  0.3809795\n",
       "  1e-04   1e-01  100      0.5038082  0.5484095  0.3825479\n",
       "  1e-04   1e-01  150      0.5038192  0.5483956  0.3825651\n",
       "  1e-01   0e+00   50      0.5004883  0.5525652  0.3811379\n",
       "  1e-01   0e+00  100      0.5032441  0.5489914  0.3832618\n",
       "  1e-01   0e+00  150      0.5036164  0.5484805  0.3836458\n",
       "  1e-01   1e-04   50      0.4994898  0.5540856  0.3801974\n",
       "  1e-01   1e-04  100      0.5019415  0.5507256  0.3824526\n",
       "  1e-01   1e-04  150      0.5022832  0.5502643  0.3827303\n",
       "  1e-01   1e-01   50      0.4944915  0.5615921  0.3763063\n",
       "  1e-01   1e-01  100      0.4968181  0.5585630  0.3783087\n",
       "  1e-01   1e-01  150      0.4968811  0.5584575  0.3783832\n",
       "\n",
       "Tuning parameter 'eta' was held constant at a value of 0.3\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final values used for the model were nrounds = 50, lambda = 0.1, alpha\n",
       " = 0.1 and eta = 0.3."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "6.17883993711594"
      ],
      "text/latex": [
       "6.17883993711594"
      ],
      "text/markdown": [
       "6.17883993711594"
      ],
      "text/plain": [
       "[1] 6.17884"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fitControl <- trainControl(## 10-fold CV\n",
    "                           method = \"repeatedcv\",\n",
    "                           number = 2,\n",
    "                           ## repeated ten times\n",
    "                           repeats = 2,\n",
    ")\n",
    "xgbLinear_predictor <- train(log_trip_duration ~ distHaversine + pickup_longitude + pickup_latitude + dropoff_longitude + dropoff_latitude , data = training, \n",
    "                 method = \"xgbLinear\"\n",
    "                )\n",
    "testing$prediction = predict(xgbLinear_predictor, testing)\n",
    "testing$error = abs(testing$log_trip_duration - testing$prediction)\n",
    "\n",
    "xgbLinear_predictor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgbLinear variable importance\n",
       "\n",
       "                  Overall\n",
       "distHaversine     0.77379\n",
       "pickup_longitude  0.06880\n",
       "dropoff_latitude  0.06187\n",
       "dropoff_longitude 0.04902\n",
       "pickup_latitude   0.04652"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgbLinear_predictor_imp <- varImp(xgbLinear_predictor, scale = FALSE)\n",
    "xgbLinear_predictor_imp\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
